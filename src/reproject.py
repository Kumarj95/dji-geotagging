'''File to use extrinsics generated by main.py along with intrinsics provided by the user to reproject object detection results to CRS of choosing'''


from argparse import ArgumentParser 
import pandas as pd
import numpy as np
from glob import glob
import os
import json
import cv2
import rasterio
from tqdm import tqdm
from pyproj import Transformer
from Utils import R_x,R_y, R_z, dsm_height
from collections import ChainMap            
from pathlib import Path

FIELDS=['fn','class','score','x1','y1','x2','y2','image_path']


def main(args):

    suffix="_output"

    json_path="demo_final.json"

    add_ids=False


    OutputPath="demo/drone1_detections_all_reprojected/"

    # detections=["/home/kumar/SmartToScripts/Documents/Work/SmartTO-York/Bolton/Data/05-07/Drone1/predictions_output_all/DJI_20250507151649_0018_D_output.txt",
    #                  "/home/kumar/SmartToScripts/Documents/Work/SmartTO-York/Bolton/Data/05-07/Drone1/predictions_output_all/DJI_20250507152056_0019_D_output.txt"]
    # detections= "../SmartToScripts/Documents/Work/SmartTO-York/Bolton/Data/05-07/Drone1_Trucks_GT/image_paths/"
    detections= "demo/drone1_detections_all/"

    dsm_path= "/home/kumar/SmartToScripts/Documents/Work/SmartTO-York/Bolton/Data/DSM_New/dsm_reproj.tif"

    ds = rasterio.open(dsm_path)
    dsm     = ds.read(1).astype(np.float32)    # 2-D array in memory
    T       = ds.transform                     # affine (x, y) <-> (row, col)
    Tinv = ~T                                      # rasterio trick: invert affine
    nrows, ncols = dsm.shape  
    src_crs = "EPSG:4326"       # lat/lon on WGS84
    tgt_crs = "EPSG:32617"      # UTM zone 17N
    transformer = Transformer.from_crs(src_crs, tgt_crs, always_xy=True)

    with open(json_path,'r') as f:
        extrinsic_info= json.load(f)
        if(isinstance(extrinsic_info, list)):
            extrinsic_info=dict(ChainMap(*extrinsic_info))
    camera_to_gimbal=np.array([[0, 0, 1], [1, 0, 0], [0, 1, 0]])
    ned_to_enu= np.array([[0, 1, 0], [1, 0, 0], [0, 0, -1]])

    intrinsics= {"fx": 2835.016147477985, 
                "fy": 2837.266860178909, 
                "cx": 1092.440583593499, 
                "cy": 1931.475403239639, 
                "skew": -0.393332100290136, 
                "k1": 0.142821807742562, 
                "k2": -0.477892606554982, 
                "k3": 0.599039059780735, 
                "p1": 0.0009153725930095632, 
                "p2": 0.000866995876388925}      

    K = np.array([
            [intrinsics['fx'], intrinsics['skew'], intrinsics['cx']],
            [0, intrinsics['fy'], intrinsics['cy']],
            [0, 0, 1] ])
    
    if(type(detections)==str and os.path.isdir(detections)):
        detections= glob(f"{detections}/*{suffix}.txt")
    elif(type(detections)==str and not os.path.isdir(detections)):
        raise RuntimeError("Detections must be a path to a directory or a list of paths ")
    elif(type(detections)!=list):
        raise RuntimeError("Detections must be a path to a directory or a list of paths ")


    if(OutputPath is None):
        OutputPath= os.path.dirname(detections[0])
    else:
        Path(OutputPath).mkdir(parents=True, exist_ok=True)

    for detection_file in detections:
        video_name=os.path.basename(detection_file).replace(suffix,"").split(".")[0]
        if video_name in extrinsic_info:
            info= extrinsic_info[os.path.basename(video_name)]
            df = pd.read_csv(detection_file, sep=" ", header=None)
            num_columns = len(df.columns)  
            df.columns=FIELDS[:num_columns]         

            frame_by_frame= df['fn'].is_monotonic_increasing
            frames=np.asarray(list(info['Frames'].keys()),dtype=np.int16)
            
            detections_reprojection=[]
            times=[]
            extra_info=[]
            print(video_name, frame_by_frame)
            if(frame_by_frame):
                iters=frames
            else:
                iters= range(len(df))

            for i in tqdm(iters):
                if(frame_by_frame):
                    frame_info=info['Frames'][str(i)]
                    frame_detection= df[df['fn']==i].to_numpy()
                    frame_time=frame_info['timestamp']
                else:
                    frame_detection=df.iloc[i]
                    if(str(int(frame_detection.fn)) in info['Frames']):
                        frame_info= info['Frames'][str(int(frame_detection.fn))]
                        frame_time=frame_info['timestamp']
                        frame_detection=frame_detection.to_numpy()[None,:]
                    else:
                        frame_detection=np.empty((0,0))
                if(frame_detection.shape[0]>0):
                    x,y_,w,h = frame_detection[:,3], frame_detection[:,4], frame_detection[:,5], frame_detection[:,6]
                    # if(has_image_path):
                    extra_information=frame_detection[:,7:]
                    u= x.reshape(-1,1)
                    v= y_.reshape(-1,1)
                    uv_undist=cv2.undistortPoints(
                                np.stack([u, v], axis=-1).astype(np.float32).reshape(-1,1,2),
                                K,  # <- OpenCV uses this internally
                                np.array([intrinsics["k1"],intrinsics["k2"],intrinsics["p1"],intrinsics["p2"],intrinsics["k3"]]),P=K
                    )[:,0]


                    lat,lon,alt = frame_info['latitude'],frame_info['longitude'],frame_info['abs_alt']                
                    d_cam = np.concatenate(
                            [uv_undist, np.ones((uv_undist.shape[0],1))], axis=1)
                    d_cam=(np.linalg.inv(K) @ d_cam.T).T
                    d_cam=(camera_to_gimbal@d_cam.T).T
                    y = np.deg2rad(frame_info['f_yaw'])
                    p = np.deg2rad(frame_info['g_pitch'])
                    r = np.deg2rad(frame_info['g_roll'])
                    R = R_z(y) @ R_y(p) @ R_x(r)
                    d_body= (R @ d_cam.T).T
                    d_worlds= (ned_to_enu@d_body.T).T
                    Camera_world= np.asarray([lat,lon,alt])
                    Camera_world=transformer.transform(Camera_world[1], Camera_world[0], Camera_world[2])
                    steps=100
                    N=d_worlds.shape[0]
                    s      = np.zeros(N, dtype=np.float32)+0.5
                    active = np.ones(N, dtype=bool)
                    hits   = np.full((N,3), np.nan, dtype=np.float32)
                    dirs=np.asarray(d_worlds)
                    origins=np.asarray(Camera_world)
                    q=0
                    while active.any() and q< steps:                             # loop until everyone is done
                        idx   = np.where(active)[0]                 # indices of still-marching rays
                        C_act = origins                       # (M,3)  M = active.sum()
                        d_act = dirs[idx]
                        s_act = s[idx][:, None]                     # column vector so broadcast works
                        # ---- march these M rays one coarse step ------------------------------
                        P = C_act + s_act * d_act                  # (M,3)
                        dz = dsm_height(dsm,P[:, 0], P[:, 1],Tinv, nrows, ncols) # vectorised bilinear

                        new_hits = P[:, 2] <= dz                   # geometric test, NaNs fail automatically

                        # write back only where a hit just happened
                        if new_hits.any():
                            hits[idx[new_hits]]   = P[new_hits]    # first-hit XYZ
                            active[idx[new_hits]] = False          # deactivate those rays
                            # pbar.update(np.count_nonzero(new_hits))
                        # increment distance only for the rays that will continue marching
                        altitude = P[:,2] - dz
                        s[idx] += np.clip(altitude*0.2, 0.5,20)
                        q=q+1
                    mask   = ~np.isnan(hits[:,0])
                    P_hit  = hits[mask]      

                    size= 10 
                    reprojected_detections=np.zeros((P_hit.shape[0],size))
                    reprojected_detections[:,0]=frame_detection[:,0][mask]
                    reprojected_detections[:,1]=frame_detection[:,1][mask]
                    reprojected_detections[:,2]= frame_detection[:,2][mask]
                    reprojected_detections[:,3:6] =P_hit
                    reprojected_detections[:,6]=frame_detection[:,5][mask]
                    reprojected_detections[:,7]=frame_detection[:,6][mask]
                    reprojected_detections[:,8]=x[mask]
                    reprojected_detections[:,9]=y_[mask]
                    # if(has_image_path):
                    # print(frame_detection)
                    extra_info.extend(list(extra_information[mask]))
                    # reprojected_detections[:,10]=frame_time
                    times.extend(P_hit.shape[0]*[frame_time])
                    # video_names.extend(P_hit.shape[0]* [video_name])
                    detections_reprojection.append(reprojected_detections)
                    # print('yo')
            detections_reprojection=np.vstack(detections_reprojection)
            # if(not has_image_path):
            reprojected_df=pd.DataFrame(detections_reprojection, columns=['fn','class','score','X','Y','Z','w','h','u','v'])
            # else:
            #     reprojected_df=pd.DataFrame(detections_reprojection, columns=['fn','class','score','X','Y','Z','w','h','u','v','image_path'])
            reprojected_df['Timestamp']=times
            reprojected_df['VideoName'] = video_name
            # if(has_image_path):
            reprojected_df[FIELDS[7:len(df.columns)]]=extra_info
            # print(reprojected_df)

            # reprojected_dfs.append(reprojected_df)
            # print('yo')
            # print(f"{OutputPath}/{os.path.basename(detection_file).split('.')[0]}_reprojected.txt")
            reproj_text_path=f"{OutputPath}/{os.path.basename(detection_file).split('.')[0]}_reprojected.txt"
            reproj_csv_path=f"{OutputPath}/{os.path.basename(detection_file).split('.')[0]}_reprojected.csv"
            reproj_pkl_path=f"{OutputPath}/{os.path.basename(detection_file).split('.')[0]}_reprojected.pkl"
            reprojected_df.to_csv(reproj_text_path,sep= " ", index=False)
            reprojected_df[['X','Y']].index.name="GEOID"
            reprojected_df[['X','Y']].to_csv(reproj_csv_path,sep= ",", index=True)
            reprojected_df.to_pickle(reproj_pkl_path)


            # reprojected_df.to_pickle()
            # if("0017" in video_name):
            #     print(video_name)
            #     print(list(video_info['frames'].keys())[0])
            #     input()
        else:
            print(f"Video {video_name} not in {json_path}")



if __name__=="__main__":

    main(None)
