'''File to use extrinsics generated by main.py along with intrinsics provided by the user to reproject object detection results to CRS of choosing'''


from argparse import ArgumentParser 
import pandas as pd
import numpy as np
from glob import glob
import os
import json
import cv2
import rasterio
from tqdm import tqdm
from pyproj import Transformer
from Utils import R_x,R_y, R_z, dsm_height
from collections import ChainMap            
from pathlib import Path

FIELDS=['fn','class','score','x1','y1','x2','y2','image_path']


def main(args):


    # json_path="demo_final.json"

    add_ids=False


    OutputPath=args.OutputPath

    detections= args.Detections

    dsm_path= args.DSM
    ds = rasterio.open(dsm_path)
    dsm     = ds.read(1).astype(np.float32)    # 2-D array in memory
    T       = ds.transform                     # affine (x, y) <-> (row, col)
    Tinv = ~T                                      # rasterio trick: invert affine
    nrows, ncols = dsm.shape  
    src_crs = f"EPSG:{args.SrcCRS}"       # lat/lon on WGS84
    tgt_crs = f"EPSG:{args.TgtCRS}"      # UTM zone 17N
    transformer = Transformer.from_crs(src_crs, tgt_crs, always_xy=True)

    with open(args.JsonPath,'r') as f:
        extrinsic_info= json.load(f)
        if(isinstance(extrinsic_info, list)):
            extrinsic_info=dict(ChainMap(*extrinsic_info))
    camera_to_gimbal=np.array([[0, 0, 1], [1, 0, 0], [0, 1, 0]])
    ned_to_enu= np.array([[0, 1, 0], [1, 0, 0], [0, 0, -1]])

    with open(args.Intrinsics, 'r') as f:
        intrinsics=json.load(f)            
                     
                     

    K = np.array([
            [intrinsics['fx'], intrinsics['skew'], intrinsics['cx']],
            [0, intrinsics['fy'], intrinsics['cy']],
            [0, 0, 1] ])
    
    if(type(detections)==str and os.path.isdir(detections)):
        detections= glob(f"{detections}/*{args.Suffix}.txt")
    elif(type(detections)==str and not os.path.isdir(detections)):
        raise RuntimeError("Detections must be a path to a directory or a list of paths ")
    elif(type(detections)!=list):
        raise RuntimeError("Detections must be a path to a directory or a list of paths ")


    if(OutputPath is None):
        OutputPath= os.path.dirname(detections[0])
    else:
        Path(OutputPath).mkdir(parents=True, exist_ok=True)

    for detection_file in detections:
        video_name=os.path.basename(detection_file).replace(args.Suffix,"").split(".")[0]
        if video_name in extrinsic_info:
            info= extrinsic_info[os.path.basename(video_name)]
            df = pd.read_csv(detection_file, sep=" ", header=None)
            num_columns = len(df.columns)  
            df.columns=FIELDS[:num_columns]         

            frame_by_frame= df['fn'].is_monotonic_increasing
            frames=np.asarray(list(info['Frames'].keys()),dtype=np.int16)
            
            detections_reprojection=[]
            times=[]
            extra_info=[]
            print(video_name, frame_by_frame)
            if(frame_by_frame):
                iters=frames
            else:
                iters= range(len(df))

            for i in tqdm(iters):
                if(frame_by_frame):
                    frame_info=info['Frames'][str(i)]
                    frame_detection= df[df['fn']==i].to_numpy()
                    frame_time=frame_info['timestamp']
                else:
                    frame_detection=df.iloc[i]
                    if(str(int(frame_detection.fn)) in info['Frames']):
                        frame_info= info['Frames'][str(int(frame_detection.fn))]
                        frame_time=frame_info['timestamp']
                        frame_detection=frame_detection.to_numpy()[None,:]
                    else:
                        frame_detection=np.empty((0,0))
                if(frame_detection.shape[0]>0):
                    x,y_,w,h = frame_detection[:,3], frame_detection[:,4], frame_detection[:,5], frame_detection[:,6]
                    # if(has_image_path):
                    extra_information=frame_detection[:,7:]
                    u= x.reshape(-1,1)
                    v= y_.reshape(-1,1)
                    uv_undist=cv2.undistortPoints(
                                np.stack([u, v], axis=-1).astype(np.float32).reshape(-1,1,2),
                                K,  # <- OpenCV uses this internally
                                np.array([intrinsics["k1"],intrinsics["k2"],intrinsics["p1"],intrinsics["p2"],intrinsics["k3"]]),P=K
                    )[:,0]


                    lat,lon,alt = frame_info['latitude'],frame_info['longitude'],frame_info['abs_alt']                
                    d_cam = np.concatenate(
                            [uv_undist, np.ones((uv_undist.shape[0],1))], axis=1)
                    d_cam=(np.linalg.inv(K) @ d_cam.T).T
                    d_cam=(camera_to_gimbal@d_cam.T).T
                    y = np.deg2rad(frame_info['f_yaw'])
                    p = np.deg2rad(frame_info['g_pitch'])
                    r = np.deg2rad(frame_info['g_roll'])
                    R = R_z(y) @ R_y(p) @ R_x(r)
                    d_body= (R @ d_cam.T).T
                    d_worlds= (ned_to_enu@d_body.T).T
                    Camera_world= np.asarray([lat,lon,alt])
                    Camera_world=transformer.transform(Camera_world[1], Camera_world[0], Camera_world[2])
                    steps=100
                    N=d_worlds.shape[0]
                    s      = np.zeros(N, dtype=np.float32)+0.5
                    active = np.ones(N, dtype=bool)
                    hits   = np.full((N,3), np.nan, dtype=np.float32)
                    dirs=np.asarray(d_worlds)
                    origins=np.asarray(Camera_world)
                    q=0
                    while active.any() and q< steps:                             # loop until everyone is done
                        idx   = np.where(active)[0]                 # indices of still-marching rays
                        C_act = origins                       # (M,3)  M = active.sum()
                        d_act = dirs[idx]
                        s_act = s[idx][:, None]                     # column vector so broadcast works
                        # ---- march these M rays one coarse step ------------------------------
                        P = C_act + s_act * d_act                  # (M,3)
                        dz = dsm_height(dsm,P[:, 0], P[:, 1],Tinv, nrows, ncols) # vectorised bilinear

                        new_hits = P[:, 2] <= dz                   # geometric test, NaNs fail automatically

                        # write back only where a hit just happened
                        if new_hits.any():
                            hits[idx[new_hits]]   = P[new_hits]    # first-hit XYZ
                            active[idx[new_hits]] = False          # deactivate those rays
                            # pbar.update(np.count_nonzero(new_hits))
                        # increment distance only for the rays that will continue marching
                        altitude = P[:,2] - dz
                        s[idx] += np.clip(altitude*0.2, 0.5,20)
                        q=q+1
                    mask   = ~np.isnan(hits[:,0])
                    P_hit  = hits[mask]      

                    size= 10 
                    reprojected_detections=np.zeros((P_hit.shape[0],size))
                    reprojected_detections[:,0]=frame_detection[:,0][mask]
                    reprojected_detections[:,1]=frame_detection[:,1][mask]
                    reprojected_detections[:,2]= frame_detection[:,2][mask]
                    reprojected_detections[:,3:6] =P_hit
                    reprojected_detections[:,6]=frame_detection[:,5][mask]
                    reprojected_detections[:,7]=frame_detection[:,6][mask]
                    reprojected_detections[:,8]=x[mask]
                    reprojected_detections[:,9]=y_[mask]
                    # if(has_image_path):
                    # print(frame_detection)
                    extra_info.extend(list(extra_information[mask]))
                    # reprojected_detections[:,10]=frame_time
                    times.extend(P_hit.shape[0]*[frame_time])
                    # video_names.extend(P_hit.shape[0]* [video_name])
                    detections_reprojection.append(reprojected_detections)
                    # print('yo')
            detections_reprojection=np.vstack(detections_reprojection)
            # if(not has_image_path):
            reprojected_df=pd.DataFrame(detections_reprojection, columns=['fn','class','score','X','Y','Z','w','h','u','v'])
            # else:
            #     reprojected_df=pd.DataFrame(detections_reprojection, columns=['fn','class','score','X','Y','Z','w','h','u','v','image_path'])
            reprojected_df['Timestamp']=times
            reprojected_df['VideoName'] = video_name
            # if(has_image_path):
            reprojected_df[FIELDS[7:len(df.columns)]]=extra_info
            # print(reprojected_df)

            # reprojected_dfs.append(reprojected_df)
            # print('yo')
            # print(f"{OutputPath}/{os.path.basename(detection_file).split('.')[0]}_reprojected.txt")
            reproj_text_path=f"{OutputPath}/{os.path.basename(detection_file).split('.')[0]}_reprojected.txt"
            reproj_csv_path=f"{OutputPath}/{os.path.basename(detection_file).split('.')[0]}_reprojected.csv"
            reproj_pkl_path=f"{OutputPath}/{os.path.basename(detection_file).split('.')[0]}_reprojected.pkl"
            reprojected_df.to_csv(reproj_text_path,sep= " ", index=False)
            reprojected_df[['X','Y']].index.name="GEOID"
            reprojected_df[['X','Y']].to_csv(reproj_csv_path,sep= ",", index=True)
            reprojected_df.to_pickle(reproj_pkl_path)


            # reprojected_df.to_pickle()
            # if("0017" in video_name):
            #     print(video_name)
            #     print(list(video_info['frames'].keys())[0])
            #     input()
        else:
            print(f"Video {video_name} not in {args.JsonPath}")


def get_parser():
    parser= ArgumentParser()

    parser.add_argument("JsonPath", help="Path to the json file with the extrinsics", type=str)
    parser.add_argument("--Detections",help="Path to a directory containing the detections files or a list of detection paths", nargs="+", type=str)
    parser.add_argument("--DSM", help="Path to DSM to get elevation data", type=str, default="demo/DSM/dsm_reproj.tif")
    parser.add_argument("--SrcCRS", help="Code for source CRS (should be the number following EPSG)", type=int, default=4326)
    parser.add_argument("--TgtCRS", help="Code for target CRS (should be the number following EPSG)", type=int, default=32617)
    parser.add_argument("--OutputPath", help="Path to output directory", type=str)
    parser.add_argument("--Intrinsics", help="Path to drone intrinsics", type=str, default="demo/drone1_intrinsics.json")
    parser.add_argument("--Suffix", help="Common suffix for all detection files", type=str, default="_output")


    parser.add_argument("--SRTPaths", help="Space seperated list of paths to SRT files", nargs="+")
    parser.add_argument("--FrameIndex", help="Number of frames to skip in first video of log file (if the video contains pitching down motion, default 1)", type=int, default=[1], nargs="+")
    parser.add_argument("--VideoDir", help="Path to directory containing videos corresponding to SRT files required for extracting frames", type=str)
    parser.add_argument("--SaveJson", help="If to save results in json format", action='store_true', default=False)
    parser.add_argument("--JsonPath", help="Path to save json to leave blank for default save", type=str)
    parser.add_argument("--SaveFrames", help="If to save the frames of the video individually", action='store_true', default=False)
    parser.add_argument("--FrameDirectory", help="Directory to save frames to",  type=str)
    parser.add_argument("--TargetGimbal", help="What gimbal angle we we are targetting for our frames",  type=float, default=-69)
    parser.add_argument("--FPS", help="Our video FPS (and how often to interpolate the log file)",  type=float, default=30)
    parser.add_argument("--Timezone", help="Timezone for timestamps",  type=str, default="America/Toronto")
    parser.add_argument("--SamplingRate", help="Sampling rate to save frames at", type=int, default=100)
    parser.add_argument("--Portrait", help="If video was shot in portrait", action="store_true", default=False)
    parser.add_argument("--CameraModel", help="Camera model of drone (useful for downstream photometry tasks)", type=str, default="FC8482")
    parser.add_argument("--Template", help="Template jpg file to copy metadata from", type=str, default="Template/DJI_0419.JPG")

    return parser

def preprocess_args(args):
    
    if len(args.Detections) == 1 :
        if(not os.path.isdir(args.Detections[0])):
            raise RuntimeError(f"{args.Detections[0]} not a directory")
        else:
            args.Detections= str(args.Detections[0])

    else:
        bad = [f for f in args.Detections if not os.path.isfile(f)]
        if bad:
            raise RuntimeError(f"--Detections expects existing files, but {bad} not found")
        
    return args


if __name__=="__main__":
    parser = get_parser()
    args = parser.parse_args()

    args= preprocess_args(args)

    main(args)
